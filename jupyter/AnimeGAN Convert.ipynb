{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60af374e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bowserj/anaconda3/lib/python3.9/site-packages/torch/hub.py:267: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/bryandlee/animegan2-pytorch/zipball/main\" to /home/bowserj/.cache/torch/hub/main.zip\n",
      "Downloading: \"https://github.com/bryandlee/animegan2-pytorch/raw/main/weights/paprika.pt\" to /home/bowserj/.cache/torch/hub/checkpoints/paprika.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98f128dfc1b4ed490952cfb69707418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/8.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load(\"bryandlee/animegan2-pytorch\", \"generator\", pretrained=\"paprika\").eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590b523d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (block_a): Sequential(\n",
       "    (0): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (1): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
       "      (2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (1): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((0, 1, 0, 1))\n",
       "      (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (2): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (block_b): Sequential(\n",
       "    (0): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((0, 1, 0, 1))\n",
       "      (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (1): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (block_c): Sequential(\n",
       "    (0): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (1): InvertedResBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): ConvNormLReLU(\n",
       "          (0): ReflectionPad2d((0, 0, 0, 0))\n",
       "          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (1): ConvNormLReLU(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=256)\n",
       "          (2): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): ConvNormLReLU(\n",
       "          (0): ReflectionPad2d((0, 0, 0, 0))\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (1): ConvNormLReLU(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), groups=512)\n",
       "          (2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): ConvNormLReLU(\n",
       "          (0): ReflectionPad2d((0, 0, 0, 0))\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (1): ConvNormLReLU(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), groups=512)\n",
       "          (2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): ConvNormLReLU(\n",
       "          (0): ReflectionPad2d((0, 0, 0, 0))\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (1): ConvNormLReLU(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), groups=512)\n",
       "          (2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (5): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (block_d): Sequential(\n",
       "    (0): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (1): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (block_e): Sequential(\n",
       "    (0): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (1): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (2): ConvNormLReLU(\n",
       "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (1): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
       "      (2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (out_layer): Sequential(\n",
       "    (0): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ca036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ce846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('packraft.png').convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1adf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = to_tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a97d7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = image_input * 2 - 1\n",
    "image_input = image_input.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e1a8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_out = model.forward(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e316175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = im_out.squeeze(0).clip(-1, 1) * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7d7bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = to_pil_image(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "931d00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b31d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "x = torch.randn(1, 3, 512, 512, requires_grad=True)\n",
    "torch_out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3632c2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bowserj/.cache/torch/hub/bryandlee_animegan2-pytorch_main/model.py:96: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if align_corners:\n",
      "/home/bowserj/.cache/torch/hub/bryandlee_animegan2-pytorch_main/model.py:102: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if align_corners:\n",
      "/home/bowserj/anaconda3/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /home/bowserj/pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/bowserj/anaconda3/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at /home/bowserj/pytorch/torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1895.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/bowserj/anaconda3/lib/python3.9/site-packages/torch/onnx/utils.py:687: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /home/bowserj/pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/bowserj/anaconda3/lib/python3.9/site-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at /home/bowserj/pytorch/torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1895.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/bowserj/anaconda3/lib/python3.9/site-packages/torch/onnx/utils.py:1178: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /home/bowserj/pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/bowserj/anaconda3/lib/python3.9/site-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at /home/bowserj/pytorch/torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1895.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "# Open ended Height and Width\n",
    "# Export the model\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"animegan_paprika.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=14,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size', 2: 'height', 3 : 'width'},    # variable length axes (required for batching)\n",
    "                                'output' : {0 : 'batch_size', 2: 'height', 3 : 'width'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c00f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open ended Height and Width\n",
    "# Export the model\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"animegan_paprika_constraned.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=14,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True  # whether to execute constant folding for optimization\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05fb157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "import torch.backends._nnapi.prepare\n",
    "\n",
    "# Input to the model\n",
    "dummy_input = torch.rand(1, 3, 512, 512)\n",
    "torchscript_model = torch.jit.trace(model, dummy_input)\n",
    "torchscript_model_optimized = optimize_for_mobile(torchscript_model)\n",
    "torch.jit.save(torchscript_model_optimized, \"animegan2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c033522",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_last_model = model.to(memory_format=torch.channels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e8ce62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NHWC Model\n",
    "dummy_input_last = torch.rand(1, 512, 512, 3)\n",
    "traced_script_module = torch.jit.trace(chan_last_model, dummy_input)\n",
    "traced_script_module_optimized = optimize_for_mobile(traced_script_module)\n",
    "torch.jit.save(traced_script_module_optimized, \"animegan2_nhwc.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dfeff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MESA-INTEL: warning: Performance support disabled, consider sysctl dev.i915.perf_stream_paranoid=0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Vulkan NCHW Backend\n",
    "nchw_script_module_optimized = optimize_for_mobile(torchscript_model, backend='vulkan')\n",
    "torch.jit.save(nchw_script_module_optimized, \"animegan_vulkan_nchw.pt\")\n",
    "\n",
    "#Vulkan NHWC Backend\n",
    "traced_script_module_vulkan_optimized = optimize_for_mobile(traced_script_module, backend='vulkan')\n",
    "torch.jit.save(traced_script_module_vulkan_optimized, \"animegan_vulkan_nhwc.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b9288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
